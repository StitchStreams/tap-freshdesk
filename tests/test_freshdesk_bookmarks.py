import re
import os
import pytz
import time
import dateutil.parser

from datetime import timedelta
from datetime import datetime

from tap_tester import menagerie, connections, runner

from base import FreshdeskBaseTest


class FreshdeskBookmarks(FreshdeskBaseTest):
    """Test incremental replication via bookmarks (without CRUD)."""

    start_date = ""

    @staticmethod
    def name():
        return "tt_freshdesk_bookmarks"

    def get_properties(self):
        return_value = {
            #'start_date':  dt.today() - timedelta(days=5*365),
            'start_date':  '2016-02-09T00:00:00Z',
            #'start_date':  '2022-02-04T00:00:00Z',
            #'start_date_with_fmt': dt.strftime(start_date, self.START_DATE_FORMAT),
        }

        self.start_date = return_value['start_date']
        return return_value

    def calculated_states_by_stream(self, current_state):
        """
        Look at the bookmarks from a previous sync and set a new bookmark
        value based off timedelta expectations. This ensures the subsequent sync will replicate
        at least 1 record but, fewer records than the previous sync.

        Sufficient test data is required for this test to cover a given stream.
        An incremental replication stream must have at least two records with
        replication keys that differ by some time span.

        If the test data is changed in the future this may break expectations for this test.
        """
        timedelta_by_stream = {stream: [2,0,0]  # {stream_name: [days, hours, minutes], ...}
                               for stream in self.expected_streams()}
        # Works with static start date to go back to 2017 Feb 8 22:xx:xx and pick up all but the
        # first record including 2 of 3 conversations assocated with those first 5 ticket records
        #timedelta_by_stream['tickets'] = [698, 17, 26]  # original conversations math, must update
        timedelta_by_stream['tickets'] = [698, 0, 0]
        timedelta_by_stream['companies'] = [0, 0, 10]
        timedelta_by_stream['agents'] = [0, 1, 0]

        #timedelta_by_stream['conversations'] = [1, 0 , 0]  # Child stream of tickets, no bookmarks
        # TODO Add conversations,time_entries, satisfaction_ratings streams

        # BUG https://jira.talendforge.org/browse/TDL-17559.  Redefining state to be closer to
        # expected format so the underlying code wont have to change as much after the JIRA fix
        current_state = {'bookmarks': current_state}
        del current_state['bookmarks']['tickets_deleted']  # Delete unexpected streams
        del current_state['bookmarks']['tickets_spam']     # generated by filter?

        # Keep existing format for this method so it will work after bug fix
        stream_to_calculated_state = {stream: "" for stream in current_state['bookmarks'].keys()}
        for stream, state_value in current_state['bookmarks'].items():
            state_as_datetime = dateutil.parser.parse(state_value)

            days, hours, minutes = timedelta_by_stream[stream]
            calculated_state_as_datetime = state_as_datetime - timedelta(days=days, hours=hours, minutes=minutes)

            state_format = self.BOOKMARK_FORMAT
            calculated_state_formatted = datetime.strftime(calculated_state_as_datetime, state_format)
            if calculated_state_formatted < self.start_date:
                raise RuntimeError("Time delta too large for stream {}, sim start_date < start_date!".format(stream))
            stream_to_calculated_state[stream] = calculated_state_formatted

        return stream_to_calculated_state

    def test_run(self):
        """A Bookmarks Test"""
        # All streams will sync but assertions only run against test_streams
        test_streams = {'tickets', 'companies', 'agents', 'groups', 'roles'}

        expected_replication_keys = self.expected_replication_keys()
        expected_replication_methods = self.expected_replication_method()

        ##########################################################################
        ### First Sync
        ##########################################################################

        conn_id = connections.ensure_connection(self)

        # Run in check mode
        check_job_name = self.run_and_verify_check_mode(conn_id)

        # Run a sync job using orchestrator
        first_sync_record_count = self.run_and_verify_sync(conn_id)
        first_sync_messages = runner.get_records_from_target_output()
        first_sync_bookmarks = menagerie.get_state(conn_id)

        ##########################################################################
        ### Update State Between Syncs
        ##########################################################################

        #new_states = {'bookmarks': dict()}        # BUG TDL-17559
        simulated_states = self.calculated_states_by_stream(first_sync_bookmarks)
        # for stream, new_state in simulated_states.items():        # BUG TDL-17559
        #     new_states['bookmarks'][stream] = new_state  # Save expected format
        # menagerie.set_state(conn_id, new_states)
        menagerie.set_state(conn_id, simulated_states)

        ##########################################################################
        ### Second Sync
        ##########################################################################

        second_sync_record_count = self.run_and_verify_sync(conn_id)
        second_sync_messages = runner.get_records_from_target_output()
        second_sync_bookmarks = menagerie.get_state(conn_id)

        ##########################################################################
        ### Test By Stream
        ##########################################################################

        #for stream in expected_streams:
        for stream in test_streams:  # Add supported streams 1 by 1
            with self.subTest(stream=stream):

                # expected values
                expected_replication_method = expected_replication_methods[stream]

                # collect information for assertions from syncs 1 & 2 base on expected values
                first_sync_count = first_sync_record_count.get(stream, 0)
                second_sync_count = second_sync_record_count.get(stream, 0)
                first_sync_records = [record.get('data') for record in
                                       first_sync_messages.get(stream).get('messages')
                                       if record.get('action') == 'upsert']
                second_sync_records = [record.get('data') for record in
                                        second_sync_messages.get(stream).get('messages')
                                        if record.get('action') == 'upsert']
                first_bookmark_value = first_sync_bookmarks.get(stream)
                second_bookmark_value = second_sync_bookmarks.get(stream)

                if expected_replication_method == self.INCREMENTAL:

                    # collect information specific to incremental streams from syncs 1 & 2
                    replication_key = next(iter(expected_replication_keys[stream]))
                    simulated_bookmark_value = simulated_states[stream]

                    # Verify the first sync sets a bookmark of the expected form
                    self.assertIsNotNone(first_bookmark_value)
                    #self.assertIsNotNone(first_bookmark_value.get(replication_key))

                    # Verify the second sync sets a bookmark of the expected form
                    self.assertIsNotNone(second_bookmark_value)
                    #self.assertIsNotNone(second_bookmark_value.get(replication_key))

                    # Verify the second sync bookmark is Equal to the first sync bookmark
                    self.assertEqual(second_bookmark_value, first_bookmark_value) # assumes no changes to data during test

                    # Verify the number of records in the 2nd sync is less then the first
                    if stream == 'roles':  # 4 records with same timestamp cannot update w test account
                        self.assertEqual(second_sync_count, first_sync_count)
                    else:
                        self.assertLess(second_sync_count, first_sync_count)

                    # Verify the bookmark is the max value sent to the target for a given replication key.
                    rec_time = []
                    for record in first_sync_records:
                        rec_time += record['updated_at'],

                    rec_time.sort()
                    self.assertEqual(rec_time[-1], first_bookmark_value)

                    rec_time = []
                    for record in second_sync_records:
                        rec_time += record['updated_at'],

                    rec_time.sort()
                    self.assertEqual(rec_time[-1], second_bookmark_value)

                    # Verify all replication key values in sync 2 are greater than or equal to the simulated bookmark value.
                    for record in second_sync_records:
                        self.assertTrue(record['updated_at'] >= simulated_states[stream],
                                        msg="record time cannot be less than bookmark time"
                        )


                # No full table streams for freshdesk as of Jan 31 2022
                else:

                    raise NotImplementedError(
                        "INVALID EXPECTATIONS\t\tSTREAM: {} REPLICATION_METHOD: {}".format(stream, expected_replication_method)
                    )


                # Verify at least 1 record was replicated in the second sync
                self.assertGreater(second_sync_count, 0, msg="We are not fully testing bookmarking for {}".format(stream))
